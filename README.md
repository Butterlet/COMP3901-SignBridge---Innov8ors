# COMP3901-SignBridge - Innov8ors

Group Members: Paris Wolfe, Ayesha Rowe, Selcon Zhang, Jonoi Graham, Malik Mittoo 

Project Description:

The problem we are addressing is the communication barrier faced by deaf and hard-of-hearing 
individuals when interacting with people who do not know sign language, especially in everyday 
environments such as schools, hospitals, and public services. 

Our proposed solution is a system that uses computer vision and machine learning to recognize 
sign language gestures through a camera and translate them into readable text and spoken output 
in real time. This allows sign language users to communicate more easily without relying on a 
human interpreter for basic interactions. 

For the scope of our project, we will focus on either: Fingerspelling using the alphabet, or a 
defined set of common signs such as “hello”, “thank you”, and “help,” to ensure that the system 
is accurate, reliable, and achievable within the capstone timeframe. 

Technological Stack: Back end: Python              
                               Front end: OpenCV (Webcam) 
 
Also, MediaPipe Hands for hand landmark detection and scikit-learn (Python library that lets us 
teach the computer to recognize patterns). 
